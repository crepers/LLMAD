{
"cells": [
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "# Interactive Machine Data Analysis\n",
      "This notebook demonstrates how to run the LLMAD anomaly detection on Machine data."
    ]
  },
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "### 1. Load Environment Variables\n",
      "\n",
      "First, we load the necessary environment variables from the `.env` file, such as API keys and the model engine to be used."
    ]
  },
  {
    "cell_type": "code",
  "execution_count": 1,
  "metadata": {},
  "outputs": [
    {
      "name": "stdout",
      "output_type": "stream",
      "text": [
        "Using Model: gemini-2.5-pro\n"
      ]
    }
  ],
  "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# You can check the loaded variables here\n",
    "print(f\"Using Model: {os.getenv('MODEL_ENGINE')}\")"
  ]
},
{
  "cell_type": "markdown",
  "metadata": {},
  "source": [
    "### 2. Set Experiment Parameters\n",
    "\n",
    "Configure the parameters for the analysis."
  ]
},
{
  "cell_type": "code",
  "execution_count": null,
  "metadata": {},
  "outputs": [],
  "source": [
    "WINDOW_SIZE = 400\n",
    "PROMPT_MODE = 5 # For Machine dataset\n",
    "DATA_ROOT_DIR = \"data/machine\"\n",
    "SAVE_DIR = \"result/machine_test\"\n",
    "VALUE_COL = \"param1\"\n",
    "LABEL_COL = \"label\"\n",
    "TEST_RATIO = 0.0001\n",
    "RETRIEVE_POSITIVE_NUM = 0\n",
    "RETRIEVE_NEGATIVE_NUM = 0\n",
    "DATA_DESCRIPTION = \"The data contains sensor readings from a machine.\"\n",
    "MAX_WORKERS = 5 # Number of parallel workers"
  ]
},
{
  "cell_type": "code",
  "execution_count": 3,
  "metadata": {},
  "outputs": [
    {
      "name": "stdout",
      "output_type": "stream",
      "text": [
        "Results will be saved in: result/machine_test/Machine_interactive_prompt_5_win_100_gemini_202512070818\n"
      ]
    }
  ],
  "source": [
    "import datetime\n",
    "\n",
    "# Get model name for suffix from environment variables\n",
    "model_engine_name = os.getenv(\"MODEL_ENGINE\", \"unknown_model\")\n",
    "# Extract the main part of the model name for the suffix (e.g., 'gpt' or 'gemini')\n",
    "model_suffix = model_engine_name.split('-')[0]\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "# Construct the run name for organization\n",
    "RUN_NAME = f\"Machine_interactive_prompt_{PROMPT_MODE}_win_{WINDOW_SIZE}_{model_suffix}_{timestamp}\"\n",
    "\n",
    "# Create the target directory for results\n",
    "RESULT_DIR = os.path.join(SAVE_DIR, RUN_NAME)\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Results will be saved in: {RESULT_DIR}\")"
  ]
},
{
  "cell_type": "markdown",
  "metadata": {},
  "source": [
    "## 3. Run Inference\n",
    "Run the LLMAD model on the data."
  ]
},
{
  "cell_type": "code",
  "execution_count": null,
  "metadata": {},
  "outputs": [
    {
      "name": "stdout",
      "output_type": "stream",
      "text": [
        "Building retrieval database:   0%|                        | 0/1 [00:00<?, ?it/s]Affine transformation is disabled. Applying simple min-max scaling.\n",
        "Building retrieval database: 100%|███████████████| 1/1 [06:37<00:00, 397.32s/it]\n",
        "Total anomaly examples in database: 0\n",
        "Found 1 files to process.\n",
        "\n",
        "[1/1] Processing file: param021\n",
        "Affine transformation is disabled. Applying simple min-max scaling.\n",
        " -> Data loaded and preprocessed.\n",
        " -> Preparing retrieval data (normal/anomaly examples)...\n",
        " -> Found 35807 normal examples and 0 anomaly examples.\n",
        "   -> Processing window 1 / 1...\n",
        "      -> Calling LLM for anomaly detection...\n",
        "      -> LLM response received. Saving results...\n",
        "   -> Processing window 2 / 1...\n",
        "      -> Calling LLM for anomaly detection...\n",
        "      -> LLM response received. Saving results...\n",
        "   -> Processing window 3 / 1...\n",
        "^C\n",
        "Traceback (most recent call last):\n",
        "  File \"/Users/woochul/workplace/wcjung/github/LLMAD/src/main.py\", line 234, in <module>\n",
        "    main(args)\n",
        "  File \"/Users/woochul/workplace/wcjung/github/LLMAD/src/main.py\", line 228, in main\n",
        "    process_file(file, run_dir_abs, ad_list, ad_str_list, ad_label_list, args)\n",
        "  File \"/Users/woochul/workplace/wcjung/github/LLMAD/src/main.py\", line 209, in process_file\n",
        "    run_inference_on_window(data_window, T_list, ad_list, ad_str_list, ad_label_list, prompt_template, base_dir, args)\n",
        "  File \"/Users/woochul/workplace/wcjung/github/LLMAD/src/main.py\", line 104, in run_inference_on_window\n",
        "    normal_series, scores, _ = find_most_similar_series_fast(X, T_list, top_k=args.retrieve_negative_num, dist_div_len=args.dist_div_len)\n",
        "  File \"/Users/woochul/workplace/wcjung/github/LLMAD/src/retriever.py\", line 24, in find_most_similar_series_fast\n",
        "    score = fast_dtw_distance(X, Y, dist_div_len)\n",
        "  File \"/Users/woochul/workplace/wcjung/github/LLMAD/src/retriever.py\", line 10, in fast_dtw_distance\n",
        "    distance, path = fastdtw(series1, series2, dist=lambda x, y: np.linalg.norm(x - y))\n",
        "  File \"/Users/woochul/workplace/wcjung/github/LLMAD/.venv/lib/python3.14/site-packages/fastdtw/fastdtw.py\", line 53, in fastdtw\n",
        "    return __fastdtw(x, y, radius, dist)\n",
        "  File \"/Users/woochul/workplace/wcjung/github/LLMAD/.venv/lib/python3.14/site-packages/fastdtw/fastdtw.py\", line 75, in __fastdtw\n",
        "    return __dtw(x, y, window, dist=dist)\n",
        "  File \"/Users/woochul/workplace/wcjung/github/LLMAD/.venv/lib/python3.14/site-packages/fastdtw/fastdtw.py\", line 142, in __dtw\n",
        "    D[i, j] = min((D[i-1, j][0]+dt, i-1, j), (D[i, j-1][0]+dt, i, j-1),\n",
        "  File \"/Users/woochul/workplace/wcjung/github/LLMAD/.venv/lib/python3.14/site-packages/fastdtw/fastdtw.py\", line 143, in <lambda>\n",
        "    (D[i-1, j-1][0]+dt, i-1, j-1), key=lambda a: a[0])\n",
        "KeyboardInterrupt\n"
      ]
    }
  ],
  "source": [
    "# 현재 data/machine/param021.parquet 파일의 총 행 수는 57,292,177개 (약 5,700만 개) 입니다.\n",
    "!python src/main.py \\\n",
    "    --infer_data_path {DATA_ROOT_DIR} \\\n",
    "    --retreive_data_path {DATA_ROOT_DIR} \\\n",
    "    --sub_company all \\\n",
    "    --window_size {WINDOW_SIZE} \\\n",
    "    --prompt_mode {PROMPT_MODE} \\\n",
    "    --result_save_dir {SAVE_DIR} \\\n",
    "    --run_name {RUN_NAME} \\\n",
    "    --value_col {VALUE_COL} \\\n",
    "    --label_col {LABEL_COL} \\\n",
    "    --prompt_extra_cols Machine Stage \\\n",
    "    --data_description \"{DATA_DESCRIPTION}\" \\\n",
    "    --no_affine_transform \\\n",
    "    --retrieve_positive_num {RETRIEVE_POSITIVE_NUM} \\\n",
    "    --retrieve_negative_num {RETRIEVE_NEGATIVE_NUM} \\\n",
    "    --cross_retrieve False \\\n",
    "    --test_ratio {TEST_RATIO} \\\n",
    "    --max_workers {MAX_WORKERS}"
  ]
},
{
  "cell_type": "markdown",
  "metadata": {},
  "source": [
    "## 4. Evaluate Metrics\n",
    "\n",
    "After the detection process is complete, run the evaluation script to calculate performance metrics."
  ]
},
{
  "cell_type": "code",
  "execution_count": null,
  "metadata": {},
  "outputs": [],
  "source": [
    "!python Eval/Eval_machine.py --path {RESULT_DIR}"
  ]
},
{
  "cell_type": "markdown",
  "metadata": {},
  "source": [
    "### 5. Visualize the Results Directly\n",
    "\n",
    "This section provides the code to visualize the results directly within this notebook. The code below will find the `predict.csv` files in the result directory and plot them."
  ]
},
{
  "cell_type": "code",
  "execution_count": null,
  "metadata": {},
  "outputs": [],
  "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "%matplotlib inline\n",
    "\n",
    "# Find all predict.csv files in the result directory\n",
    "predict_files = glob.glob(os.path.join(RESULT_DIR, '**', 'predict.csv'), recursive=True)\n",
    "\n",
    "print(f\"Searching for result files in: {RESULT_DIR}\")\n",
    "print(f\"Found {len(predict_files)} result file(s) to visualize.\")\n",
    "\n",
    "for file_path in predict_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if df.empty:\n",
    "            print(f\"Skipping empty file: {file_path}\")\n",
    "            continue\n",
    "            \n",
    "        # Extract file name/directory from path\n",
    "        file_name = os.path.basename(os.path.dirname(file_path))\n",
    "        \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.plot(df['value'], label='Value', alpha=0.7, color='blue')\n",
    "        \n",
    "        # Highlight anomalies\n",
    "        if 'predict' in df.columns:\n",
    "            anomalies = df[df['predict'] == 1]\n",
    "            plt.scatter(anomalies.index, anomalies['value'], color='red', label='Predicted Anomaly', zorder=5)\n",
    "            \n",
    "        if 'label' in df.columns:\n",
    "            true_anomalies = df[df['label'] == 1]\n",
    "            plt.scatter(true_anomalies.index, true_anomalies['value'], marker='x', color='green', label='True Anomaly', s=50, zorder=6)\n",
    "        \n",
    "        # Add metadata to title if available\n",
    "        title = f'Anomaly Detection Results: {file_name}'\n",
    "        if 'Machine' in df.columns and not df['Machine'].empty:\n",
    "            machine = df['Machine'].iloc[0]\n",
    "            title += f\" | Machine: {machine}\"\n",
    "        if 'Stage' in df.columns and not df['Stage'].empty:\n",
    "            stage = df['Stage'].iloc[0]\n",
    "            title += f\" | Stage: {stage}\"\n",
    "            \n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"First 5 rows of {file_name}:\")\n",
    "        display(df.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing {file_path}: {e}\")"
  ]
}
],
"metadata": {
"kernelspec": {
  "display_name": ".venv",
  "language": "python",
  "name": "python3"
},
"language_info": {
  "codemirror_mode": {
    "name": "ipython",
    "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.14.0"
}
},
"nbformat": 4,
"nbformat_minor": 4
}
